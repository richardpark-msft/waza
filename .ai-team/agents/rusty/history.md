# Project Context

- **Owner:** Shayne Boyer (spboyer@live.com)
- **Project:** Waza â€” Go CLI for evaluating AI agent skills (scaffolding, compliance scoring, cross-model testing)
- **Project:** Waza â€” Go CLI for evaluating AI agent skills
- **Stack:** Go, Cobra CLI, Copilot SDK, YAML specs
- **Created:** 2026-02-09

## Learnings

<!-- Append new learnings below. Each entry is something lasting about the project. -->
ğŸ“Œ Team update (2026-02-11): Run command tests must reset package-level flag vars (contextDir, outputPath, verbose) at top of each test body to prevent state leakage. â€” decided by Linus
<!-- Append new learnings below. -->

### 2026-02-11: PR #111 Review â€” tokens compare command
- **Author:** Charles Lowell (chlowell), branch `tokens-compare`
- **Verdict:** Approved. Clean implementation of `waza tokens compare` (E4, closes #51).
- **Architecture:** New `internal/git` package under `cmd/waza/tokens/internal/git/` â€” well-bounded, not importable outside tokens tree.
- **Quality:** Comprehensive tests with real git repos in temp dirs, table-driven subtests. Reuses existing `EstimatingCounter`, `NormalizePath`, `nowISO`.
- **Nit:** `RefExists()` is dead code (defined but never called). Non-blocking.
- **CI:** Green â€” both build/test and lint passed.

### 2026-02-11: PR #112 Review â€” --show-unchanged applied to JSON output
- **Author:** Charles Lowell (chlowell), branch `unchanged-json`
- **Verdict:** Approved. Tight follow-up to PR #111 (+12/-13, single file).
- **Change:** Lifts `--show-unchanged` filtering from `compareTable` up to `runCompare`, so it applies to both table and JSON output. Summary computed before filtering so totals remain correct.
- **Quality:** Uses `slices.DeleteFunc` (Go 1.21+ stdlib) â€” replaces manual filter loop. `compareTable` simplified by removing `showUnchanged` parameter.
- **Tests:** Existing tests cover both paths. No new tests needed â€” the filtering is now shared code exercised by table-output tests.
- **CI:** Green â€” both build/test and lint passed.

### 2026-02-11: PR #113 Review â€” azd extension release pipeline
- **Author:** Wallace Breza (wbreza), branch `feat/azd-ext-release-pipeline`
- **Verdict:** Changes requested. Two blocking issues, three suggestions.
- **Blocking:** (1) Version downgrade 0.1.0â†’0.0.2 â€” semver should only move forward, needs justification or fix. (2) Registry checksum/tag mismatch â€” URLs reference `_0.1.0` tag but version is being set to 0.0.2.
- **Suggestions:** Move validation scripts out of repo root (`scripts/`); clarify `.github/skills/` vs `skills/` convention for workflow-automation skills; add trailing newline to `version.txt`.
- **Good:** Pipeline structure (workflow_dispatch â†’ build â†’ pack â†’ release â†’ publish â†’ auto-merge registry PR), permissions minimized, all 6 platform targets, `GH_TOKEN` from `secrets.GITHUB_TOKEN`, SKILL.md well-structured with user prompts at decision points, both bash and PowerShell validation scripts.
- **Alignment:** Directly advances E7 (AZD Extension). Completes release automation story started in PR #103.
- **CI:** No checks reported on the branch (new workflow only, no Go code changes).

### 2026-02-11: PR #114 Review â€” tokens suggest command
- **Author:** Charles Lowell (chlowell), branch `tokens-suggest`
- **Verdict:** Changes requested. Three lint issues blocking CI.
- **Blocking:** (1) `errcheck` â€” `engine.Shutdown` return value unchecked in `suggest.go`. (2) `errcheck` â€” `filepath.Rel` return value unchecked in copilot goroutine. (3) `misspell` â€” `analyses`/`Analyses` flagged as misspelling of `analyzes`/`Analyzes` (6 occurrences across suggest.go and suggest_test.go).
- **Architecture:** Two-mode design (heuristic + copilot) with `newChatEngine` function variable for test injection. Semaphore-bounded concurrency (`maxCopilotWorkers=4`). Prompt embedded via `//go:embed`. Refactored `countFile` â†’ `countTokens` as pure function shared across count/check/suggest. Moved `countLines` from `compare.go` to `helpers.go`.
- **Quality:** 17 test functions, comprehensive fixture set under `testdata/suggest/`, mock engine integration, JSON/text output, edge cases. Heuristic checks align with sensei reference (emojis, code blocks, tables, duplicates, horizontal rules, limit violations).
- **Size:** +1137/-34 â€” substantial but well-scoped.
- **CI:** Build/test green. Lint failing (3 categories above).
- **Lesson:** golangci-lint's misspell checker treats "analyses" (valid English noun) as a misspelling of "analyzes". Watch for this in future PRs â€” either rename variables or suppress with nolint directive.

### 2026-02-11: PR #115 Review â€” azd extension metadata capability
- **Author:** Wallace Breza (wbreza), branch `feat/metadata-capability`
- **Verdict:** Changes requested. Two blocking CI failures, three non-blocking suggestions.
- **Blocking:** (1) `gofmt` â€” both `cmd_metadata.go` and `cmd_metadata_test.go` have formatting issues. (2) `go 1.25` version bump in `go.mod` breaks golangci-lint v1.64.8 (built with Go 1.24, refuses Go 1.25 targets). Either pin to a Go 1.24-compatible azd module version or upgrade golangci-lint in CI.
- **Architecture:** Hidden `metadata` Cobra command calls `azdext.GenerateExtensionMetadata()` â€” pure introspection, no side effects, writes JSON to stdout. Uses canonical azd types, no custom converters. Wired via `cmd.AddCommand(newMetadataCommand(cmd))` in root.go. `extension.yaml` adds `metadata` to capabilities list.
- **Quality:** 4 tests covering JSON validity/schema, expected commands, flag population, and hidden status. Clean separation â€” single 32-line file for the command.
- **Concern:** The `azd` module pulls ~60 transitive dependencies (OpenTelemetry, gRPC, protobuf, Azure SDK). Significant weight increase for a previously lightweight CLI. Acceptable for canonical integration, but should migrate to standalone `azdext` module if one is published.
- **Alignment:** Directly advances E7 (AZD Extension). Completes metadata discovery story alongside PR #113 (release pipeline).
- **CI:** Both build/test and lint failing (gofmt + golangci-lint version mismatch).
- **Lesson:** When adding dependencies that require a Go version bump, check that CI toolchain (especially golangci-lint) supports the new version. Coordinate go.mod and CI workflow changes in the same PR.

ğŸ“Œ Team update (2026-02-12): azd-publish skill location convention â€” repo-level skills go under `.github/skills/`, project eval skills go under `skills/`. â€” decided by Wallace Breza
ğŸ“Œ Team update (2026-02-12): azd extension uses tag pattern `azd-ext-microsoft-azd-waza_VERSION`, not `vVERSION`. â€” decided by Linus
ğŸ“Œ Team update (2026-02-12): PR #115 review feedback addressed â€” Linus rebased, resolved conflicts, added doc comments per review. â€” decided by Linus
### 2026-02-11: PR #117 Review â€” waza dev command (E2: Sensei Engine)
- **Author:** Charles Lowell (chlowell), branch `waza-dev`
- **Verdict:** APPROVED. Clean, well-architected implementation of the Sensei development loop. Closes #32, #33, #35.
- **Epic:** E2 (Sensei Engine) â€” Iterative skill improvement with heuristic scoring
- **Architecture:** Four-package structure:
  - `cmd/waza/dev/` â€” CLI (root.go, loop.go, score.go, display.go, prompt.go) with clear separation: orchestration, heuristics, formatting, user input
  - `internal/skill/` â€” New SKILL.md parser with `TextMarshaler`/`TextUnmarshaler` for YAML round-trip, preserves unknown fields
  - `internal/tokens/` â€” Extracted token estimation logic (surgical refactor: import path changes only, no logic modifications)
  - Tests: 61 functions across 6 test files (display, score, loop, prompt, skill, tokens)
- **Heuristic Scoring:** Correctly implements Sensei reference rules: Low â†’ Medium (desc 150+ chars + triggers) â†’ Medium-High (+ anti-triggers) â†’ High (+ routing clarity). Pattern detection validates against real fixtures (code-explainer=Low, waza=High).
- **Ralph Loop:** Iterates through description expansion â†’ triggers â†’ anti-triggers â†’ routing clarity. Correctly skips inapplicable steps; declining suggestion advances to next step (not terminating). Enforces soft (500) and hard (5000) token limits.
- **Code Quality:** Idiomatic Go â€” interface-based scorer for test injection, functional error wrapping (%w), clean naming, well-commented. Prompt state handling (shared bufio.Scanner) prevents stdin clobbering across multiple user prompts. Display formatting includes box-drawing characters, emoji width awareness, rune-aware truncation.
- **Test Coverage:** Table-driven pattern matching tests, edge cases (nil skill, over-length descriptions, token budgets), real fixture loading, comprehensive testdata (high, valid, minimal, no-frontmatter).
- **Alignment:** âœ… E2 epic, âœ… issues #32-35, âœ… sensei reference patterns, âœ… Ralph loop discipline
- **CI:** Both build/test and lint passing (no errcheck, gofmt, or misspell violations)
- **Recommendation:** Merge immediately. Implementation demonstrates deep understanding of Sensei architecture and Go conventions. No rework needed. Post-merge: consider future --strict flag for hard-limit exit code (E4 scope).

### 2026-02-11: PR #117 Deep Review (second opinion, opus-4.6)
- **Verdict:** Confirmed approval. First review was accurate on architecture, scoring correctness, and test quality.
- **New findings (all non-blocking):**
  1. **TriggerCount vs HasTriggers mismatch** â€” `HasTriggers` matches 4 patterns but `TriggerCount` only counts after "USE FOR:". Display can show "Triggers: 0" while scoring Medium. UX confusion, not a scoring bug.
  2. **parseFrontmatter closing delimiter fragile** â€” `strings.Index(rest, "\n---")` could split prematurely on multiline YAML scalars containing `---`. Safe during round-trip (yaml.Marshal escapes), edge case for hand-crafted files.
  3. **writeSkillFile not atomic** â€” `os.WriteFile` without temp+rename. Ctrl+C during write could truncate. Low risk.
  4. **No context.Context** â€” Will need retrofit when Copilot-based suggestions (#36) land.
  5. **suggestTriggers semantic duplicates** â€” Name + heading overlap produces redundant phrases. Cosmetic.
  6. **boxLine emoji width** â€” Rune count â‰  terminal column width for âœ…/âŒ. Acknowledged in code comments.
- **Suggestions:** count all trigger patterns (not just "USE FOR:"), atomic writes, context.Context plumbing, --dry-run flag, tests for non-existent path and --target low.
- **Copilot reviewer alignment:** 3 of 4 inline comments were valid (trigger count mismatch, parser fragility, comment/code mismatch). The 4th was a typo fix.
- **Lesson:** Deep reviews catch UX inconsistencies and future-proofing gaps that fast-model reviews miss, but the fast model correctly identified all structural and correctness aspects.

ğŸ“Œ Team update (2026-02-15): Review @copilot PRs with claude-opus-4.6 before merging â€” quality gate for doc PRs. â€” decided by Shayne Boyer
ğŸ“Œ Team update (2026-02-15): Auto-assign unblocked work to squad/@copilot. Don't ask, just assign and go. â€” decided by Shayne Boyer
ğŸ“Œ Team update (2026-02-15): After feature PRs merge (CLI, graders, YAML format, examples), route doc updates to Saul. Issue #148 tracks this. â€” decided by Shayne Boyer
ğŸ“Œ Team update (2026-02-15): All developers use claude-opus-4.6. For code review, if developer isn't using Opus, reviewer uses it. â€” decided by Shayne Boyer
ğŸ“Œ Team update (2026-02-15): Don't take assigned work. Only pick up unassigned issues. â€” decided by Shayne Boyer
ğŸ“Œ Team update (2026-02-15): Multi-model execution is sequential (not parallel). Test failures non-fatal so all models complete. â€” decided by Linus
ğŸ“Œ Team update (2026-02-15): Microsoft/skills repo moving to plugin bundle structure. CI must support both flat and nested layouts. â€” decided by Shayne Boyer

### 2026-02-15: PR #152 Review â€” --model flag for multi-model evaluation (#39)
- **Author:** Linus (Backend Dev), branch `squad/39-multi-model-support`
- **Verdict:** APPROVE WITH NITS. Clean implementation, two non-blocking issues.
- **Epic:** E3 (Evaluation Framework) â€” Closes #39 [E3-01] Support multiple model execution.
- **Architecture:** `runSingleModel()` extraction is well-structured â€” each model gets its own engine instance, runner, and context. Spec mutation (`spec.Config.ModelID = modelID`) in the loop is safe because `runSingleModel` reads it only at creation time. Error handling distinguishes `TestFailureError` (continue in multi-model) from infrastructure errors (abort immediately). `sanitizeModelName()` handles `/`, `\`, `:`, space. Per-model JSON output uses `base_model.ext` naming.
- **Nits found:** (1) Comparison table `%-10.1f%%` format puts a gap between value and `%` sign (cosmetic). (2) `runSingleModel` creates engine but never calls `engine.Shutdown()` â€” pre-existing issue (also absent on main), not introduced by this PR.
- **Test coverage:** 9 tests + 3 subtests covering flag parsing, override, multi-model, backward compat, comparison table output, edge cases. `resetRunGlobals()` correctly includes `modelOverrides = nil`.
- **CI:** Build clean, go vet clean, all tests pass (including all pre-existing tests unchanged).
- **Lesson:** When extracting a loop body into a helper, always verify resource lifecycle (init/defer-shutdown) is preserved per iteration. In this case, engine.Shutdown() was already missing upstream, so the extraction didn't regress.

### 2026-02-15: E3 Evaluation Framework Backlog Triage
- **Task:** Assess four unassigned E3 issues and recommend prioritization
- **Issues triaged:** #44 (suggestions), #106 (tool_call rubrics), #107 (task rubrics), #138 (multi-model recommendations)
- **Key findings:**
  1. **#44 ready NOW** â€” Charles already extracted suggestion engine in PR #117. Main work: consolidate into `internal/suggestions/` package shared by `waza dev` and `waza run --suggestions`. No blockers. Assign to Linus.
  2. **#106 & #107 blocked by #104** â€” Both port Azure ML `.prompty` templates to YAML rubrics. Identical structure, work in parallel after #104 merges. Assign to Livingston (docs-integration role fits).
  3. **#138 blocked by #39 + #104** â€” Capstone E3 feature (multi-model recommendations). #39 merged (PR #152). Waiting on #104 prompt grader stability. Needs design clarity: What are optimization dimensions? (cost/quality/latency/consistency?)
- **Critical blocker:** #104 (prompt grader) unblocks 3 of 4 issues downstream. Recommend prioritizing in parallel track.
- **Architecture decisions captured:**
  - Suggestion engine must be a shared package, not duplicated in `waza dev` and `waza run`.
  - Azure ML porting establishes reusable rubric YAML pattern â€” capture for future evaluators.
  - Recommendation engine requires explicit rubric design (dimensions) before prompt engineering.
- **Deliverable:** Triage analysis written to `.ai-team/decisions/inbox/rusty-eval-backlog-triage.md`
ğŸ“Œ Team update (2026-02-15): Don't take assigned work â€” only pick up unassigned issues â€” decided by Shayne Boyer
ğŸ“Œ Team update (2026-02-15): Engine shutdown fix (#153) complete â€” merged 21 tests from Basher covering all exit paths. Critical path blocker #104 (Prompt Grader) unblocks 50% of E3 backlog. â€” Rusty (Lead)
