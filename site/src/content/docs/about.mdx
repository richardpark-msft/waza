---
title: About
description: About waza, architecture, and how to contribute.
---

## What is Waza?

**Waza** (æŠ€ - Japanese for "skill/technique") is a unified CLI platform for creating, testing, and evaluating AI agent skills.

It consolidates existing skill development tools into a single binary that provides the complete developer experience for creating, testing, and improving AI agent skills across any domain or platform.

## The Problem

Creating, testing, and evaluating AI agent skills lacks consistent tooling:

- **Automated compliance validation** â€” No standardized scoring to ensure skill quality
- **Trigger testing** â€” Manual verification of skill activation patterns
- **Cross-model evaluation** â€” No framework for testing skills across GPT-4o, Claude, etc.
- **Token budget enforcement** â€” Guidelines exist but aren't automatically checked

## The Solution

Waza automates the skill development workflow:

| Phase | Capability |
|-------|-----------|
| **Scaffold** | Generate a compliant skill structure ready for evaluation |
| **Develop** | Iterate with real-time compliance scoring |
| **Test** | Run agentic test loops with real LLM execution |
| **Evaluate** | Cross-model comparison with comprehensive metrics |

## Architecture

Waza is built in **Go** for:
- Single-binary distribution (no dependencies)
- Fast execution
- Cross-platform compatibility (Linux, macOS, Windows)

### Components

```
waza/
â”œâ”€â”€ cmd/waza/              # CLI entrypoint
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ config/            # Configuration
â”‚   â”œâ”€â”€ execution/         # Agent engines
â”‚   â”œâ”€â”€ models/            # Data structures
â”‚   â”œâ”€â”€ orchestration/     # Test runner
â”‚   â””â”€â”€ scoring/           # Validators
â”œâ”€â”€ web/                   # Dashboard (React + Tailwind)
â””â”€â”€ examples/              # Example evals
```

### Design Principles

1. **Fixture Isolation** â€” Each task gets a fresh temp workspace. Original fixtures never modified.
2. **Pluggable Validators** â€” 11 grader types, easily extended
3. **Cross-Model Support** â€” Test skills against multiple LLM providers
4. **Local-First** â€” Mock executor for development, real API for CI/CD
5. **Observability** â€” Full transcripts, detailed metrics, dashboard visualization

## Key Features

### Structured Benchmarks

Define test cases in YAML:

```yaml
name: code-explainer-eval
tasks:
  - "tasks/*.yaml"

graders:
  - type: regex
    config:
      must_match: ["function", "parameter"]
```

### 11 Built-In Validators

- **Code** â€” Python assertions
- **Regex** â€” Pattern matching
- **Keyword** â€” Keyword presence
- **File** â€” Output file checking
- **Diff** â€” Diff comparison
- **JSON Schema** â€” JSON structure validation
- **Prompt** â€” LLM-powered evaluation
- **Behavior** â€” Agent behavior validation
- **Action Sequence** â€” Tool call sequence validation
- **Skill Invocation** â€” Skill invocation validation
- **Program** â€” Program execution validation

### Multi-Model Comparison

```bash
waza run eval.yaml --model gpt-4o -o gpt4.json
waza run eval.yaml --model claude-sonnet-4.6 -o sonnet.json
waza compare gpt4.json sonnet.json
```

### Interactive Dashboard

```bash
waza serve
```

Explore results, trends, and comparisons in a web interface.

### CI/CD Ready

Pre-configured GitHub Actions workflow:

```bash
waza init my-project
# Creates .github/workflows/eval.yml
```

## Contributing

We welcome contributions! Here's how to get involved:

### Report Issues

Found a bug or have a feature request?

1. Check [existing issues](https://github.com/spboyer/waza/issues)
2. Open a new issue with clear reproduction steps
3. Include error logs and environment details

### Contribute Code

1. **Fork** the repository
2. **Create a branch** for your feature: `git checkout -b feature/my-feature`
3. **Make changes** following the code style
4. **Write tests** for new functionality
5. **Run linter and tests**:
   ```bash
   make lint
   make test
   ```
6. **Commit** with clear messages: `feat: Add my feature`
7. **Push** to your fork and open a pull request

### Development Setup

```bash
# Clone repository
git clone https://github.com/spboyer/waza.git
cd waza

# Set up Go environment
go version  # Requires 1.25+

# Build
make build

# Test
make test

# Lint
make lint

# Run
./waza --help
```

### Code Style

- Follow Go idioms ([Effective Go](https://golang.org/doc/effective_go))
- Use `gofmt` for formatting
- Include unit tests for new code
- Document public functions

### Adding Validators

To add a new grader type:

1. Implement `Validator` interface in `internal/scoring/`
2. Register in `ValidatorRegistry`
3. Add tests
4. Document in README

Example:

```go
type MyValidator struct {
    Config interface{} `json:"config"`
}

func (v *MyValidator) Grade(ctx *models.GradeContext) (*models.ValidationResult, error) {
    // Implementation
}
```

### Documentation

- Update relevant docs when changing behavior
- Add examples for new features
- Keep README.md and GUIDE.md in sync

## Community

### Discussions

Have questions or ideas? Join the conversation:

- **[GitHub Discussions](https://github.com/spboyer/waza/discussions)** â€” Ask questions, share ideas
- **[GitHub Issues](https://github.com/spboyer/waza/issues)** â€” Report bugs, request features

### Support

- **Documentation:** [docs/](https://github.com/spboyer/waza/tree/main/docs)
- **Examples:** [examples/](https://github.com/spboyer/waza/tree/main/examples)

## Roadmap

### E1: Go CLI Foundation (âœ… Complete)

- âœ… waza run â€” Execute benchmarks
- âœ… waza init â€” Scaffold projects
- âœ… waza new â€” Create skills
- âœ… waza compare â€” Cross-model comparison
- âœ… All 11 grader types

### E2: Sensei Engine (ğŸŸ¡ In Progress)

- âœ… waza check â€” Compliance scoring
- âœ… waza dev â€” Iterative improvement
- ğŸŸ¡ Token budget optimization
- ğŸŸ¡ Trigger accuracy testing

### E3: Evaluation Framework (ğŸŸ¡ In Progress)

- âœ… Multi-model testing
- âœ… Comprehensive metrics
- ğŸŸ¡ Statistical analysis
- ğŸŸ¡ LLM-powered suggestions

### E4: Token Management (â³ Planned)

- Token counting across models
- Budget enforcement
- Optimization recommendations

### E5: Waza Skill (â³ Planned)

- Conversational skill interface
- Interactive development

### E6: CI/CD Integration (âœ… Complete)

- âœ… GitHub Actions workflow
- âœ… Artifact handling
- âœ… PR comments

### E7: AZD Extension (âœ… Complete)

- âœ… Azure Developer CLI integration
- âœ… Registry publishing

## License

[MIT License](https://github.com/spboyer/waza/blob/main/LICENSE)

## Author

**Shayne Boyer** ([@spboyer](https://github.com/spboyer))

Maintained by the waza team and community contributors.

---
**Questions?** [Open an issue](https://github.com/spboyer/waza/issues) or start a [discussion](https://github.com/spboyer/waza/discussions).

---

## Inspiration

The waterfall timeline visualization in the waza dashboard was inspired by the [.NET Aspire](https://learn.microsoft.com/en-us/dotnet/aspire/overview) distributed application dashboard, which provides a similar trace/span view for distributed systems observability.
